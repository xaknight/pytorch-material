{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPh28YigTOr3qm6ETaHMuIC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xaknight/pytorch-material/blob/main/beginner_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BSQue5XiGfd",
        "outputId": "30ae8cf2-e87c-45de-c3e1-cd86dca37409"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "# Official command from: https://pytorch.org/get-started/locally/\n",
        "!pip install torch torchvision torchaudio\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.cuda.is_available())  # Check GPU availability\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1P5SX3ejjiGf",
        "outputId": "6c8fa08d-42cf-42c7-a15c-4857dbd651b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Create tensors\n",
        "a = torch.tensor([1, 2, 3])\n",
        "b = torch.zeros((2, 3))\n",
        "c = torch.ones((2, 2))\n",
        "d = torch.randn((3, 3))  # Standard normal distribution\n",
        "\n",
        "# Shape & type\n",
        "print(a.shape, a.dtype)\n",
        "print(c.shape, c.dtype)\n",
        "print(b.shape, b.dtype)\n",
        "\n",
        "# Indexing & slicing\n",
        "print(d[0])          # First row\n",
        "print(d[:, 1])       # Second column\n",
        "\n",
        "# Math operations\n",
        "x = torch.tensor([1.0, 2.0, 3.0])\n",
        "y = torch.tensor([3.0, 4.0, 5.0])\n",
        "print(x + y)\n",
        "print(torch.dot(x, y))  # Dot product\n",
        "\n",
        "# Broadcasting\n",
        "A = torch.randn((3, 1))\n",
        "B = torch.randn((1, 4))\n",
        "C = A + B  # Broadcast to (3,4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ctal0zpaj72y",
        "outputId": "10d22819-1b77-4ac1-8c43-203f607259fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3]) torch.int64\n",
            "torch.Size([2, 2]) torch.float32\n",
            "torch.Size([2, 3]) torch.float32\n",
            "tensor([ 1.4111,  0.2957, -0.4695])\n",
            "tensor([ 0.2957, -1.3110, -0.1733])\n",
            "tensor([4., 6., 8.])\n",
            "tensor(26.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(A,B,C)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBVmr_9_kJ7d",
        "outputId": "d04b0d44-7f55-47ca-e257-40d8194c0c28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.2732],\n",
            "        [ 1.4888],\n",
            "        [-0.5833]]) tensor([[ 0.5971,  0.1786, -0.4253, -0.6135]]) tensor([[ 0.8703,  0.4517, -0.1521, -0.3403],\n",
            "        [ 2.0859,  1.6674,  1.0636,  0.8753],\n",
            "        [ 0.0138, -0.4047, -1.0085, -1.1968]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex = torch.rand(4,4)"
      ],
      "metadata": {
        "id": "7-nBX6s8lCFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ex)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbZUAtcylfKI",
        "outputId": "01ec260d-ee99-4735-92bd-996bb72f0ef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4849, 0.6995, 0.0761, 0.0940],\n",
            "        [0.2025, 0.0780, 0.8728, 0.9346],\n",
            "        [0.1542, 0.9934, 0.6021, 0.5192],\n",
            "        [0.5313, 0.1417, 0.6911, 0.8931]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ex.mean"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oipXU5AhlgRy",
        "outputId": "5c4e016e-454b-42fe-e966-df0f36c07df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function Tensor.mean>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "exmean = ex.mean()"
      ],
      "metadata": {
        "id": "mS8MaCcUljVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exstd = ex.std()"
      ],
      "metadata": {
        "id": "i-Fl_DNMllZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exy = (ex - exmean)/exstd"
      ],
      "metadata": {
        "id": "XKmytqw-lndo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(exy,exmean,exstd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87JKXSIalzhQ",
        "outputId": "3f5dcadc-ef4c-4175-a9a6-c28fc7559155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0392,  0.6031, -1.2634, -1.2098],\n",
            "        [-0.8848, -1.2576,  1.1221,  1.3072],\n",
            "        [-1.0295,  1.4831,  0.3117,  0.0633],\n",
            "        [ 0.0997, -1.0671,  0.5782,  1.1829]]) tensor(0.4980) tensor(0.3340)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(ex[1,1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivcft-zel0vL",
        "outputId": "6b6802dc-6a25-4844-c340-4bca2499a9ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0780)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "print((ex[1,1] - exmean)/exstd)"
      ],
      "metadata": {
        "id": "Efh3ye12mFt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: how to check cosine similarity b/w 2 vectors use pytorch for this without abstract function code it directly using torch tensors\n",
        "\n",
        "# Check cosine similarity between two vectors\n",
        "def cosine_similarity(vector1, vector2):\n",
        "    dot_product = torch.dot(vector1, vector2)\n",
        "    norm_vector1 = torch.linalg.norm(vector1)\n",
        "    norm_vector2 = torch.linalg.norm(vector2)\n",
        "    return dot_product / (norm_vector1 * norm_vector2)\n",
        "# Example usage:\n",
        "vector1 = torch.tensor([1.0, 2.0, 3.0])\n",
        "vector2 = torch.tensor([4.0, 5.0, 6.0])\n",
        "similarity = cosine_similarity(vector1, vector2)\n",
        "print(\"Cosine similarity:\", similarity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59pXaABZmstE",
        "outputId": "df7ba37e-97fe-4db8-9bf9-bd86437080ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity: tensor(0.9746)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "y = x ** 2 + 3 * x + 4\n",
        "y.backward()  # dy/dx = 2x + 3\n",
        "print(x.grad)  # Should print 7.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCWRKxzinQCK",
        "outputId": "2bfaf214-6527-40e4-972f-30e8f3f9c48c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(7.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: how to use trignometric functions for definining an equation without using tensor like y = sinx\n",
        "x1 = torch.tensor(2.0, requires_grad=True)\n",
        "import math\n",
        "\n",
        "y = torch.sin(x1**2 + 3*x1)\n",
        "y.backward()\n",
        "print(x1.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iwV47z-uC9-",
        "outputId": "59e2cd0a-f0c1-42d6-f690-11fe5f31877f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-5.8735)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Linear(2, 4)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.layer2 = nn.Linear(4, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.layer1(x))\n",
        "        return self.layer2(x)\n",
        "\n",
        "model = SimpleNet()\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tlvTLmOvTR9",
        "outputId": "f76c3b7f-8473-43ed-b136-b57fdcebcc3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleNet(\n",
            "  (layer1): Linear(in_features=2, out_features=4, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (layer2): Linear(in_features=4, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class layer3net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Linear(10,64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.layer2 = nn.Linear(64,32)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.layer3 = nn.Linear(32,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "      x = self.relu(self.layer1(x))\n",
        "      x = self.relu(self.layer2(x))\n",
        "      return self.layer3(x)\n",
        "\n",
        "model = layer3net()\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9lL_XVzv1rs",
        "outputId": "5d513796-3bcb-4a98-8a29-017a69788c79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layer3net(\n",
            "  (layer1): Linear(in_features=10, out_features=64, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (layer2): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (layer3): Linear(in_features=32, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Dataset: y = 2x + 3\n",
        "x = torch.randn((100, 1))\n",
        "# torch.randn_like(x): This generates a new tensor of the same shape and data\n",
        "# type as x. The values in this new tensor are drawn from a standard normal\n",
        "# distribution (mean 0, variance 1). This introduces randomness.\n",
        "y = 2 * x + 3 + 0.1 * torch.randn_like(x)\n",
        "\n",
        "model = nn.Linear(1, 1)\n",
        "criterion = nn.MSELoss()\n",
        "# model.parameters(): This is a crucial part. model refers to the neural network model we defined earlier. The .parameters() method of a torch.nn.Module (which our model is) returns an iterator over all the parameters (weights and biases) of the model. These are the values that the optimizer will adjust during training to minimize the loss.\n",
        "# lr=0.01: This sets the learning rate for the optimizer. The learning rate (lr)\n",
        "#  is a hyperparameter that controls the step size taken during each iteration of\n",
        "#  the optimization process. A smaller learning rate means smaller steps, which\n",
        "#  can lead to more stable training but might take longer to converge. A larger\n",
        "#   learning rate means larger steps, which can potentially converge faster but\n",
        "#    might overshoot the minimum. In this case, the learning rate is set to 0.01.\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(100):\n",
        "    pred = model(x)\n",
        "    loss = criterion(pred, y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward() # because we are optimizing for model's loss function not model function\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}: loss = {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFxSjrRjwNuJ",
        "outputId": "f331e541-171c-4372-f6bc-4a33f1751aec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: loss = 11.0806\n",
            "Epoch 10: loss = 7.7341\n",
            "Epoch 20: loss = 5.4023\n",
            "Epoch 30: loss = 3.7765\n",
            "Epoch 40: loss = 2.6422\n",
            "Epoch 50: loss = 1.8503\n",
            "Epoch 60: loss = 1.2972\n",
            "Epoch 70: loss = 0.9106\n",
            "Epoch 80: loss = 0.6403\n",
            "Epoch 90: loss = 0.4513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(), #convert ndarray to tensors and scales them\n",
        "    transforms.Normalize((0.5,), (0.5,)) #this takes the tensors and normalized them with mean = 0.5 and std = 0.5\n",
        "])\n",
        "\n",
        "mnist_train = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "train_loader = DataLoader(mnist_train, batch_size=32, shuffle=True)\n",
        "\n",
        "# Iterate through loader\n",
        "for images, labels in train_loader:\n",
        "    print(images.shape)  # [32, 1, 28, 28]\n",
        "    print(labels[0])\n",
        "    print(labels[:5])\n",
        "    break\n"
      ],
      "metadata": {
        "id": "VSXK9CnNxGWC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1927639-3ab4-42a2-fec5-8c5bfd5e163e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.46MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 160kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.52MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 3.49MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 1, 28, 28])\n",
            "tensor(0)\n",
            "tensor([0, 0, 1, 5, 0])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(784, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "model = MNISTNet()\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# Training\n",
        "for epoch in range(5):\n",
        "    for images, labels in train_loader:\n",
        "        preds = model(images)\n",
        "        loss = loss_fn(preds, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(\"epoch: \",epoch, \"Loss: \",loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRohgcgrZTFF",
        "outputId": "014ea46b-f0d6-40c6-e246-5a97ef85385f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  0 Loss:  tensor(1.5545, grad_fn=<NllLossBackward0>)\n",
            "epoch:  1 Loss:  tensor(1.5797, grad_fn=<NllLossBackward0>)\n",
            "epoch:  2 Loss:  tensor(1.5679, grad_fn=<NllLossBackward0>)\n",
            "epoch:  3 Loss:  tensor(1.4884, grad_fn=<NllLossBackward0>)\n",
            "epoch:  4 Loss:  tensor(1.5234, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: i epoch is one iteration over whole dataset am i right\n",
        "\n",
        "# Yes, you are correct. In the context of machine learning training, an \"epoch\" refers to one complete pass through the entire training dataset. During an epoch, the model sees every training example exactly once."
      ],
      "metadata": {
        "id": "PjfGoqgtbXZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "mnist_test = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
        "print(len(mnist_test))\n",
        "test_loader = DataLoader(mnist_test, batch_size=32, shuffle=True)\n",
        "for image,labels in test_loader:\n",
        "  pred = model(images)\n",
        "  print(labels,pred)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JC-UZ_0CSxU-",
        "outputId": "4a02b52b-b989-4040-bcd1-6c839510db59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n",
            "tensor([6, 4, 3, 8, 4, 4, 3, 5, 8, 5, 3, 6, 9, 1, 5, 2, 3, 9, 4, 1, 4, 6, 6, 7,\n",
            "        9, 0, 1, 1, 5, 3, 5, 1]) tensor([[6.9479e-19, 4.2942e-18, 1.0000e+00, 1.3078e-14, 4.5898e-11, 1.2358e-20,\n",
            "         1.4095e-07, 3.0121e-17, 3.0377e-16, 2.8721e-20],\n",
            "        [6.2244e-15, 1.1113e-21, 8.9457e-15, 3.0766e-10, 2.6029e-19, 2.6880e-15,\n",
            "         8.2864e-26, 1.0000e+00, 1.5815e-16, 1.7815e-08],\n",
            "        [1.0000e+00, 5.3391e-25, 9.2672e-08, 4.4366e-14, 1.8708e-18, 3.6468e-18,\n",
            "         6.3434e-16, 1.0392e-14, 4.9771e-13, 7.0154e-14],\n",
            "        [6.6156e-10, 8.0887e-08, 4.8664e-09, 1.3788e-02, 1.5243e-02, 1.4682e-09,\n",
            "         1.8412e-11, 3.1979e-07, 1.2003e-07, 9.7097e-01],\n",
            "        [2.9850e-24, 1.0000e+00, 4.7937e-09, 9.4960e-16, 3.1355e-15, 1.0028e-17,\n",
            "         8.6309e-10, 1.7455e-13, 3.8630e-08, 2.4326e-15],\n",
            "        [7.2351e-14, 1.2289e-08, 1.0771e-05, 1.3253e-09, 5.4732e-14, 1.7009e-10,\n",
            "         2.1116e-12, 1.6050e-14, 9.9999e-01, 1.5744e-08],\n",
            "        [2.0557e-16, 5.3632e-21, 1.4959e-05, 7.9758e-19, 6.5269e-14, 2.1951e-12,\n",
            "         9.9999e-01, 2.0944e-23, 6.9529e-17, 1.4449e-22],\n",
            "        [5.7694e-13, 5.6719e-16, 2.7474e-08, 4.5620e-20, 4.2741e-03, 8.1550e-11,\n",
            "         2.7421e-10, 3.4125e-07, 8.1555e-05, 9.9564e-01],\n",
            "        [3.6272e-24, 1.3919e-18, 1.0000e+00, 3.1706e-18, 1.6180e-18, 1.0863e-31,\n",
            "         3.1607e-11, 1.1304e-15, 1.5295e-20, 2.2815e-27],\n",
            "        [1.0295e-18, 1.2369e-16, 1.1475e-15, 6.9247e-11, 1.5214e-08, 3.5042e-08,\n",
            "         8.4768e-22, 1.9026e-04, 1.4122e-09, 9.9981e-01],\n",
            "        [6.7442e-18, 1.0000e+00, 1.1697e-06, 3.0625e-10, 5.8995e-13, 3.3842e-14,\n",
            "         4.9072e-08, 1.0306e-11, 6.0345e-09, 1.5735e-14],\n",
            "        [2.6584e-10, 1.0205e-08, 2.4730e-08, 3.7045e-04, 1.8767e-11, 9.9943e-01,\n",
            "         1.7936e-04, 1.0766e-16, 1.7834e-05, 7.4596e-13],\n",
            "        [1.1466e-22, 6.3405e-34, 1.3305e-24, 3.4792e-21, 2.2860e-22, 5.5129e-25,\n",
            "         6.1208e-36, 1.0000e+00, 1.3965e-17, 2.6011e-11],\n",
            "        [3.9776e-09, 7.5328e-15, 3.0231e-07, 7.9804e-14, 3.3137e-04, 9.9842e-01,\n",
            "         2.7597e-04, 3.2299e-10, 9.7402e-04, 4.3668e-07],\n",
            "        [6.5437e-23, 3.0549e-21, 2.8696e-20, 1.0000e+00, 8.7424e-18, 2.5692e-10,\n",
            "         1.3275e-31, 7.0380e-20, 1.7059e-10, 2.9262e-08],\n",
            "        [6.1105e-08, 7.2950e-08, 9.9982e-01, 1.7807e-04, 7.7850e-14, 8.1919e-11,\n",
            "         4.5727e-06, 1.0459e-08, 5.4916e-11, 4.4994e-14],\n",
            "        [2.7356e-09, 3.0568e-16, 3.1905e-13, 6.8604e-09, 7.6011e-09, 1.5641e-10,\n",
            "         3.0345e-14, 9.9937e-01, 2.6090e-13, 6.2729e-04],\n",
            "        [7.3453e-16, 2.3524e-10, 3.2888e-08, 1.6384e-09, 1.1888e-24, 1.9152e-15,\n",
            "         7.7652e-30, 1.0000e+00, 1.8193e-09, 2.1425e-08],\n",
            "        [3.4281e-19, 1.0000e+00, 1.4560e-10, 1.2301e-12, 2.9993e-16, 2.6265e-17,\n",
            "         5.1591e-16, 7.6749e-14, 9.5692e-12, 1.5930e-15],\n",
            "        [2.7643e-20, 1.0000e+00, 4.0700e-11, 4.7726e-12, 1.2764e-11, 3.5738e-20,\n",
            "         7.2978e-14, 8.8484e-10, 1.6827e-08, 2.8436e-11],\n",
            "        [2.9845e-20, 4.0561e-20, 3.5898e-16, 4.3365e-14, 5.3635e-09, 2.4255e-11,\n",
            "         6.4467e-18, 1.1618e-07, 7.4548e-13, 1.0000e+00],\n",
            "        [1.0000e+00, 1.1731e-18, 6.0361e-10, 5.1849e-12, 1.4876e-25, 4.4403e-12,\n",
            "         3.1626e-15, 4.5605e-14, 2.1169e-17, 5.0210e-16],\n",
            "        [9.7429e-28, 1.0395e-13, 9.2462e-08, 1.0000e+00, 1.9666e-20, 1.5496e-13,\n",
            "         5.4134e-22, 2.1508e-33, 4.3853e-12, 9.9593e-23],\n",
            "        [3.8172e-26, 8.6076e-16, 3.9072e-06, 9.1802e-13, 1.2690e-24, 9.8349e-25,\n",
            "         2.9382e-23, 1.0000e+00, 1.3122e-11, 3.9539e-15],\n",
            "        [2.1682e-15, 6.2374e-17, 1.4946e-14, 6.0382e-22, 1.9417e-11, 7.8995e-14,\n",
            "         1.0000e+00, 5.3904e-18, 2.9834e-11, 8.5627e-16],\n",
            "        [6.1614e-22, 1.7316e-15, 5.2130e-10, 7.8354e-18, 7.8711e-14, 2.0867e-14,\n",
            "         1.0000e+00, 4.2415e-22, 4.4528e-13, 1.1325e-20],\n",
            "        [1.5666e-17, 3.4781e-14, 2.3848e-10, 2.8659e-12, 2.1245e-17, 1.1841e-12,\n",
            "         4.6534e-16, 1.7583e-16, 1.0000e+00, 1.7399e-10],\n",
            "        [6.4721e-15, 2.4636e-14, 5.8735e-21, 1.4325e-07, 1.4540e-14, 1.0000e+00,\n",
            "         1.2505e-21, 1.1888e-11, 3.2475e-13, 5.7730e-10],\n",
            "        [2.9943e-22, 2.7101e-24, 1.8892e-12, 8.4558e-28, 8.4706e-17, 2.1228e-15,\n",
            "         1.0000e+00, 1.5201e-30, 1.8430e-16, 9.9443e-27],\n",
            "        [1.3402e-26, 3.3408e-31, 1.8620e-28, 6.0568e-12, 2.1935e-23, 1.0000e+00,\n",
            "         8.2818e-34, 3.2537e-18, 5.9872e-17, 5.5052e-10],\n",
            "        [3.6572e-16, 1.7564e-09, 8.6114e-12, 9.9999e-01, 2.7414e-14, 5.7568e-06,\n",
            "         3.9083e-15, 5.3485e-16, 7.4711e-09, 2.1322e-10],\n",
            "        [7.5319e-16, 1.5213e-09, 1.0000e+00, 4.0721e-09, 1.0514e-23, 3.2533e-17,\n",
            "         1.9333e-14, 7.2479e-25, 5.8271e-10, 1.3822e-23]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "# Load Test Data\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():  # Disable gradient calculation\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)               # Forward pass\n",
        "        preds = torch.argmax(outputs, dim=1)  # Get predicted class\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Compute Accuracy\n",
        "acc = accuracy_score(all_labels, all_preds)\n",
        "print(f\"Test Accuracy: {acc * 100:.2f}%\")\n",
        "\n",
        "# Confusion Matrix (Optional)\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "# Optional Visualization of some misclassified images\n",
        "import numpy as np\n",
        "\n",
        "def show_misclassified(model, loader):\n",
        "    model.eval()\n",
        "    misclassified = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            outputs = model(images)\n",
        "            preds = outputs.argmax(1)\n",
        "            mismatches = preds != labels\n",
        "            if mismatches.any():\n",
        "                for img, true, pred in zip(images[mismatches], labels[mismatches], preds[mismatches]):\n",
        "                    misclassified.append((img, true, pred))\n",
        "            if len(misclassified) >= 5:\n",
        "                break\n",
        "\n",
        "    # Plot\n",
        "    fig, axs = plt.subplots(1, 5, figsize=(15, 3))\n",
        "    for i, (img, true, pred) in enumerate(misclassified[:5]):\n",
        "        axs[i].imshow(img.squeeze(), cmap='gray')\n",
        "        axs[i].set_title(f'True: {true}, Pred: {pred}')\n",
        "        axs[i].axis('off')\n",
        "    plt.show()\n",
        "\n",
        "show_misclassified(model, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "RThlUBV5WI-y",
        "outputId": "f5e78caa-8a53-4e1a-b792-607c7b9bcbc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 93.94%\n",
            "Confusion Matrix:\n",
            " [[ 968    0    1    6    0    2    0    1    2    0]\n",
            " [   0 1116    2   11    0    0    2    1    3    0]\n",
            " [   2    0  976   30    5    4    5    6    3    1]\n",
            " [   1    0    4  994    0    0    0    6    4    1]\n",
            " [   2    2    4    1  913    0    9    7    5   39]\n",
            " [   8    1    1   33    1  829    9    0    6    4]\n",
            " [  13    3    4    3    2   16  914    0    3    0]\n",
            " [   3    6   21   12    2    1    1  952    0   30]\n",
            " [   4    4    5  114    3   10   10    9  812    3]\n",
            " [   5   13    1   27   10    7    1   18    7  920]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x300 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# prompt: # Assuming 'a' is a Python list or NumPy array\n",
        "# a_tensor = torch.tensor(a)\n",
        "# # Assuming 'ndarray' is a NumPy array\n",
        "# ndarray_tensor = torch.from_numpy(ndarray) difference in above numpy array below numpy array\n",
        "\n",
        "The main difference lies in how the tensor is created and whether it shares memory with the original NumPy array.\n",
        "\n",
        "*   **`torch.tensor(a)`**:\n",
        "    *   This creates a **copy** of the data in the Python list or NumPy array `a`.\n",
        "    *   The new tensor does **not** share memory with `a`.\n",
        "    *   Changes to the tensor will **not** affect the original Python list or NumPy array `a`, and vice-versa.\n",
        "    *   It infers the data type from the input data.\n",
        "\n",
        "*   **`torch.from_numpy(ndarray)`**:\n",
        "    *   This creates a tensor that **shares the same memory** as the NumPy array `ndarray`.\n",
        "    *   Changes made to the tensor **will** affect the original NumPy array `ndarray`.\n",
        "    *   Changes made to the original NumPy array `ndarray` **will** affect the tensor.\n",
        "    *   It only works with NumPy arrays, not Python lists.\n",
        "    *   The data type of the resulting tensor will match the data type of the NumPy array."
      ],
      "metadata": {
        "id": "4TyLG1n8Scsn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: converting an array a and ndarray to pytorch tensor\n",
        "a  = [1,2,3,4]\n",
        "# Assuming 'a' is a Python list or NumPy array\n",
        "a_tensor = torch.tensor(a)\n",
        "import numpy\n",
        "ndarray = numpy.array([1,23,12,3])\n",
        "# Assuming 'ndarray' is a NumPy array\n",
        "ndarray_tensor = torch.from_numpy(ndarray)\n",
        "\n",
        "print(a_tensor)\n",
        "ndarray_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_29VhfqP1SK",
        "outputId": "9ae34bb8-f927-4e0f-9d28-77ee1b8ab434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3, 4])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1, 23, 12,  3])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wfWhIbJmXQay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: what is broadcasting in pytorch write comments explaining that then show an example\n",
        "\n",
        "# Broadcasting is a mechanism in PyTorch that allows tensors with different shapes to be used in arithmetic operations.\n",
        "# It works by \"stretching\" the smaller tensor to match the shape of the larger tensor, without actually creating a copy of the data.\n",
        "# This is done by replicating the elements along the dimensions where the shapes differ and one of the dimensions is 1.\n",
        "# If the dimensions are incompatible (neither is 1 and they are different), a RuntimeError will occur.\n",
        "\n",
        "# Example of Broadcasting:\n",
        "tensor1 = torch.tensor([[1, 2, 3],\n",
        "                        [4, 5, 6]]) # Shape (2, 3)\n",
        "\n",
        "tensor2 = torch.tensor([10, 20, 30]) # Shape (3)\n",
        "\n",
        "# tensor2 will be broadcast to shape (2, 3) by replicating its rows\n",
        "result_broadcast = tensor1 + tensor2\n",
        "print(\"\\nTensor 1:\\n\", tensor1)\n",
        "print(\"Tensor 2:\\n\", tensor2)\n",
        "print(\"Result of broadcasting (tensor1 + tensor2):\\n\", result_broadcast)\n",
        "\n",
        "# Another example with different dimensions\n",
        "tensor3 = torch.tensor([[100],\n",
        "                        [200]]) # Shape (2, 1)\n",
        "\n",
        "# tensor3 will be broadcast to shape (2, 3) by replicating its columns\n",
        "result_broadcast_2 = tensor1 + tensor3\n",
        "print(\"\\nTensor 1:\\n\", tensor1)\n",
        "print(\"Tensor 3:\\n\", tensor3)\n",
        "print(\"Result of broadcasting (tensor1 + tensor3):\\n\", result_broadcast_2)\n",
        "\n",
        "# Example of incompatible shapes for broadcasting\n",
        "tensor4 = torch.tensor([1, 2]) # Shape (2)\n",
        "# result_incompatible = tensor1 + tensor4 # This would cause a RuntimeError because shapes (2, 3) and (2) are not broadcastable\n",
        "# print(result_incompatible)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Guw49kkhSkfn",
        "outputId": "05cadd23-5e5b-4b28-e40b-7369386e3671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tensor 1:\n",
            " tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "Tensor 2:\n",
            " tensor([10, 20, 30])\n",
            "Result of broadcasting (tensor1 + tensor2):\n",
            " tensor([[11, 22, 33],\n",
            "        [14, 25, 36]])\n",
            "\n",
            "Tensor 1:\n",
            " tensor([[1, 2, 3],\n",
            "        [4, 5, 6]])\n",
            "Tensor 3:\n",
            " tensor([[100],\n",
            "        [200]])\n",
            "Result of broadcasting (tensor1 + tensor3):\n",
            " tensor([[101, 102, 103],\n",
            "        [204, 205, 206]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: give me a 4,2,3 shape tensor\n",
        "# rand\n",
        "\n",
        "# 4,2,3 shape tensor\n",
        "rand_tensor = torch.rand(4, 2, 3)\n",
        "rand_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed_ZUm3GX_1i",
        "outputId": "5521cfcc-759f-4e7c-8929-8da50604e847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.4346, 0.2752, 0.2471],\n",
              "         [0.9446, 0.7720, 0.8052]],\n",
              "\n",
              "        [[0.7431, 0.9647, 0.8673],\n",
              "         [0.0681, 0.0171, 0.6431]],\n",
              "\n",
              "        [[0.7179, 0.4063, 0.2775],\n",
              "         [0.1767, 0.3131, 0.9418]],\n",
              "\n",
              "        [[0.2284, 0.1794, 0.0758],\n",
              "         [0.5189, 0.7200, 0.6002]]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C6r2xqqsYKMQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}